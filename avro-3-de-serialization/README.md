# spring-kafka-de-serialization-types
## `> avro-3-de-serialization`

![avro-3-de-serialization](../documentation/avro-3-de-serialization.jpeg)

This sample demonstrates a **producer** that pushes `News` messages to a topic in `Kafka` and a **consumer** that listens those messages from `Kafka`:
- **Producer** serializes the message `key` using `StringSerializer` and the message `value` using `KafkaAvroSerializer`;
- **Consumer** deserializes message `key` using `StringSerializer` to the message `value` using `SpecificAvroWithSchemaDeserializer`;
- This type of serialization/deserialization uses `Schema Registry`;
- The Java class generated from the `Avro` schema **DOES NOT** need to have the same `name` and `package (or namespace)` in the producer and the consumer;
- We needed to implement the `SpecificAvroWithSchemaDeserializer` class;
- **Producer** creates the Kafka topics and **Consumer** doesn't.

## Start Environment

Before starting producer and consumer, the services present in `docker-compose.yml` file must be up and running as explained in [Start Environment](https://github.com/ivangfr/spring-kafka-de-serialization-types#start-environment) section of the main README.

## Running applications using Maven

> **Note**: run `avro-3-producer-service` first so that it can create the `Kafka` topics.

- **avro-3-producer-service**

  - Open a terminal and navigate to the `spring-kafka-de-serialization-types` root folder;
  - Run application:
    ```
    ./mvnw clean spring-boot:run --projects avro-3-de-serialization/avro-3-producer-service
    ```
    > The Java class `com.ivanfranchin.avro3producerservice.avro.NewsMessage` is generated by the Avro file `news-message.avsc` present in `src/main/resources/avro` by running the command:
    > ```
    > ./mvnw generate-sources --projects avro-3-de-serialization/avro-3-producer-service
    > ```
  - As soon as the producer is up and running, it will start pushing automatically and randomly `News` messages to `Kafka` topic `avro-3-de-serialization-news`. The default `interval` between messages is `3 seconds`.

- **avro-3-consumer-service**

  - Open another terminal and make sure you are in `spring-kafka-de-serialization-types` root folder;
  - Run application:
    ```
    ./mvnw clean spring-boot:run --projects avro-3-de-serialization/avro-3-consumer-service
    ```
    > The Java class `com.ivanfranchin.avro3consumerservice.avro.NewsMessage` is generated by the Avro file `news-message.avsc` present in `src/main/resources/avro` by running the command:
    > ```
    > ./mvnw generate-sources --projects avro-3-de-serialization/avro-3-consumer-service
    > ```
  - Once the consumer is up and running, it will start listening `News` messages from the `Kafka` topic `avro-3-de-serialization-news`.

## Running applications as Docker containers

- ### Build Docker images

  In a terminal and, inside the `spring-kafka-de-serialization-types` root folder, run:
  ```
  ./build-docker-images.sh avro-3-de-serialization
  ```

- ### Environment variables

  **avro-3-producer-service** and **avro-3-consumer-service**

  | Environment Variable   | Description                                                             |
  |------------------------|-------------------------------------------------------------------------|
  | `KAFKA_HOST`           | Specify host of the `Kafka` message broker to use (default `localhost`) |
  | `KAFKA_PORT`           | Specify port of the `Kafka` message broker to use (default `29092`)     |
  | `SCHEMA_REGISTRY_HOST` | Specify host of the `Schema Registry` to use (default `localhost`)      |
  | `SCHEMA_REGISTRY_PORT` | Specify port of the `Schema Registry` to use (default `8081`)           |

- ### Run Docker containers

  > **Note**: run `avro-3-producer-service` first so that it can create the `Kafka` topics.

  - **avro-3-producer-service**

    In a terminal, run the following Docker command:
    ```
    docker run --rm --name avro-3-producer-service -p 9088:9088 \
      -e KAFKA_HOST=kafka -e KAFKA_PORT=9092 -e SCHEMA_REGISTRY_HOST=schema-registry \
      --network=spring-kafka-de-serialization-types_default \
      ivanfranchin/avro-3-producer-service:1.0.0
    ```

  - **avro-3-consumer-service**

    In another terminal, run the Docker command below:
    ```
    docker run --rm --name avro-3-consumer-service -p 9089:9089 \
      -e KAFKA_HOST=kafka -e KAFKA_PORT=9092 -e SCHEMA_REGISTRY_HOST=schema-registry \
      --network=spring-kafka-de-serialization-types_default \
      ivanfranchin/avro-3-consumer-service:1.0.0
    ```

## Shutdown

- Go to the terminals where the applications are running and press `Ctrl+C`;
- Stop the services present in `docker-compose.yml` as explained in [Shutdown](https://github.com/ivangfr/spring-kafka-de-serialization-types#shutdown) section of the main README.

## Cleanup

To remove the Docker images created by this example, go to a terminal and, inside the `spring-kafka-de-serialization-types` root folder, run the following script:
```
./remove-docker-images.sh avro-3-de-serialization
```
